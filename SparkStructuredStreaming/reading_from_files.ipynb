{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0214ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create the Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"Streaming Process Files\") \n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "    .master(\"local[*]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8af42c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# To allow automatic schemaInference while reading\n",
    "spark.conf.set(\"spark.sql.streaming.schemaInference\", True)\n",
    "\n",
    "# batch version\n",
    "# spark.read.format(\"json).load(\"data/input/device_files)\n",
    "\n",
    "# Create the streaming_df to read from input directory\n",
    "streaming_df = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .option(\"cleanSource\", \"archive\")\n",
    "    .option(\"sourceArchiveDir\", \"archive_dir\")\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .format(\"json\")\n",
    "    .load(\"data/input/device_files/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9360f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# To the schema of the data, place a sample json file and change readStream to read \n",
    "streaming_df.printSchema()\n",
    "# streaming_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3dbc3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Lets explode the data as devices contains list/array of device reading\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "exploded_df = streaming_df.withColumn(\"data_devices\", explode(\"data.devices\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d169c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check the schema of the exploded_df, place a sample json file and change readStream to read \n",
    "exploded_df.printSchema()\n",
    "#exploded_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29ea72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Flatten the exploded df\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "flattened_df = (\n",
    "    exploded_df\n",
    "    .drop(\"data\")\n",
    "    .withColumn(\"deviceId\", col(\"data_devices.deviceId\"))\n",
    "    .withColumn(\"measure\", col(\"data_devices.measure\"))\n",
    "    .withColumn(\"status\", col(\"data_devices.status\"))\n",
    "    .withColumn(\"temperature\", col(\"data_devices.temperature\"))\n",
    "    .drop(\"data_devices\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d86c9b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check the schema of the flattened_df, place a sample json file and change readStream to read \n",
    "flattened_df.printSchema()\n",
    "#flattened_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b636c6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to console sink to check the output\n",
    "\n",
    "(flattened_df\n",
    " .writeStream\n",
    " .format(\"csv\")\n",
    " .outputMode(\"append\")\n",
    " .option(\"path\", \"data/output/device_data.csv\")\n",
    " .option(\"checkpointLocation\", \"checkpoint_dir\")\n",
    " .start()\n",
    " .awaitTermination())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
